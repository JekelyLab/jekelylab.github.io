---
title: "**COS goes FOSS** <br> The sorry state of scientific publishing and how we could move to an open and resilient infrastructure"
author: "<br><br> 29 January 2026 <br><br> Gáspár Jékely <br><br> Centre for Organismal Studies, Heidelberg University"
format:
  revealjs: 
    theme: [default, custom.scss]
    slide-number: true
    code-fold: false
    code-summary: "Code"
    chalkboard: 
      buttons: false
    preview-links: auto
scrollable: true
---

## The crysis of publishing---symptomes

::: columns
:::{.column width=30%}
![](images/open_science/scientific-publishing-profit-nature-feature.jpg)
:::
:::{.column width=70%}

- reproducibility crisis
- only a small fraction of primary data available
- even smaller fraction of code
- open access, if exists, is very expensive, maintains the profit of legacy publishers
- antiquated, dysfunctional system that rewards prestige/hype over quality/integrity
- scholarly workflows use non-professional, closed-source software (MS, Adobe, Prism etc.) 
- sharing, integration, automation and collaboration difficult (who can use Git?)
- final product of years of research: pdf file (1990s tech) behind a paywall
- data, code, text not searchable, reuseable, discoverable
:::
:::

## Most source data collected by scientists are not available

<br>

![](images/Data_publication_Pyramide.png){height=450}


## Code is very often not shared or not shared stably

::: columns
:::{.column width=40%}
![](images/Stodden_PNAS.png)

- study to assess the effectiveness of code sharing policy
- random sample of 204 *Science* papers
- artifacts from 44% 
- reproduce the findings for 26%
:::
:::{.column width=60%}
- **Typical responses:**

::: {.incremental}
  - *"The data files remains our property and are not deposited for free access."*

  - *"When you approach a PI for the source codes and raw data, you better explain who you are, whom you work for, why you need the data and what you are going to do with it."*

  - *"I have to say that this is a very unusual request without any explanation! Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation."*

  - *"We do not typically share our internal data or code with people outside our collaboration."*

:::
:::
:::

::: aside
[Stodden et al. (2018) ](https://doi.org/10.1073/pnas.1708290115)
:::


## Flipped protein structures due to buggy program


::: columns
:::{.column width=40%}
![](images/open_science/MsbA_flipped.png)

*The structures of MsbA (purple) and Sav1866 (green) overlap little (left) until MsbA is inverted (right).*
:::
:::{.column width=60%}
- buggy non-published program flipped two columns, inverting electron density
- program was inherited from another lab
- mistake repeated in several papers
- led to five retractions (three in *Science*)
:::
:::

::: aside
[Miller 2006](https://www.science.org/doi/10.1126/science.314.5807.1856)
:::


## Gene name errors are widespread in the scientific literature

<br><br>

![](images/13059_2016_1044_Fig1_HTML.webp)


::: aside
[Ziemann et al. (2016)](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7)
:::

## Most scientists use software developed for accounting {transition="fade" transition-speed="fast"}

![](images/Scientists_rename_genes.png){height=14em}


- the symbol MARCH1 has now become MARCHF1
- SEPT1 has become SEPTIN1, and so on

::: aside

[theverge.com](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates)
:::

## Reporting and citation bias

::: columns
:::{.column width=50%}
![](images/open_science/citation_bias.jpeg)

- The cumulative impact of reporting and citation biases on the evidence base for antidepressants
::: 
:::{.column width=50%}
<br>

- 50% of randomized controlled trials have never been published
- trials with statistically significant findings are more likely to be published
- citation bias -> studies with positive results receive more citations than negative studies 
:::
:::

:::aside
[de Vries et al., 2018](https://www.cambridge.org/core/journals/psychological-medicine/article/cumulative-effect-of-reporting-and-citation-biases-on-the-apparent-efficacy-of-treatments-the-case-of-depression/71D73CADE32C0D3D996DABEA3FCDBF57)
:::


## Majority of high-impact cancer studies fail to replicate

::: columns
:::{.column width=50%}
![](images/open_science/cancer_replication.png)
::: 
:::{.column width=50%}
- The Reproducibility Project: Cancer Biology (RP:CB) 
- failure to replicate 30 of 53 papers published by *Science*, *Nature*, and *Cell* from 2010 to 2012
- credibility of preclinical cancer biology?
- need for authors to share more details of their experiments
- vague protocols and uncooperative authors
- one-third of contacted authors declined or did not respond

:::
:::

:::aside
[Errington et al., Reproducibility Project: Cancer Biology, 2014](https://elifesciences.org/collections/9b1e83d1/reproducibility-project-cancer-biology)
:::


## An epidemic of retractions

<br><br>

::: columns
:::{.column width=55%}
![](images/open_science/retractions_per_year.webp)
::: 
:::{.column width=40%}
- steep increase in retractions
- monitoring retractions: http://retractionwatch.com
- majority of all retractions is due to misconduct
:::
:::

:::aside
[Brembs et al. 2013](https://doi.org/10.3389/fnhum.2013.00291)
:::


## Perverse incentives, publish or perish

::: columns
:::{.column width=60%}
![](images/open_science/adoration_CNS.png)
Brembs
::: 
:::{.column width=40%}
- chasing 'stories' and IF instead of integrity, hypothesis-testing, rigour, openness
- under the spell of glamour journals
- "**If** I get this result, this will be a *Nature* paper!"
- reporting bias (only positive results are reported)
- low statistical power (a p-value of 0.05 brings only 50% reproducibility)
- in worst cases data are fabricated

:::
:::



## Impact factor - not a metric of quality

- IF = number of citations to articles in a journal (the numerator), normalized by the number of articles in that journal (the denominator) in the last 2 y
- calculated by Thomson Reuters
- originally created to help librarians, not as a measure of quality
- yet, emerged as a pervasive metric of quality
- in some cases not calculated but negotiated (the denominator, e.g Curr Biol)
- removing editorials/News-and-Views articles from the denominator (so called “front-matter”) can dramatically alter the resulting IF
- not reproducible, not open (calculated from proprietary data)
- a composite of multiple, highly diverse article types
- comparison of journals not mathematically sound

:::aside
[Brembs et al. 2013](https://doi.org/10.3389/fnhum.2013.00291)
:::

## IF - statistically flawed

::: columns
:::{.column width=60%}
![](images/open_science/if_plots.png)
::: 
:::{.column width=40%}
- highly skewed distributions
- distorted by outliers (see Nature)
- journal IF comparisons: comparison of means of two populations 
- allowed only if distributions follow a **normal distributions**! 
- simple ranking by mean is incorrect
- median would be better or a more complex statistical test (e.g. Kruskal–Wallis test)
:::
:::

:::aside
[Larivière et al. 2016](https://doi.org/10.1101/062109)
:::

## IF - strongly biased by outliers

::: columns
:::{.column width=50%}
![](images/open_science/if_model_fit.png)
::: 
:::{.column width=50%}
<br>

- fitting a more complex exponential function to the citation data
- a journal impact factor can be calculated from the parameters of the fit
- *Science* JIF = **25.3** instead of the reported **34**
- *Nature* JIF = **26.8** instead of the reported **37**
- a few highly cited papers have a substantial effect on the mean, but less on the exponential function
:::
:::

:::aside
[Berg, 2016](https://www.science.org/content/blog-post/journal-impact-factors---fitting-citation-distribution-curves)
:::

## JIF does not correlate with quality metrics (e.g. statistical power)

<br>

::: columns
:::{.column width=50%}
![](images/open_science/fnhum-07-00291-g002.jpg)
::: 
:::{.column width=50%}
- no association between statistical power and journal IF
:::
:::

:::aside
[Fang & Casadevall, 2011](https://journals.asm.org/doi/10.1128/iai.05661-11)
[Brembs et al. 2013](https://doi.org/10.3389/fnhum.2013.00291)
:::

## But: JIF correlates with retractions

<br>


::: columns
:::{.column width=50%}
![](images/open_science/retraction_IF.jpeg)
::: 
:::{.column width=50%}
- 'journal rank' is a strong predictor of the rate of retractions
- (also of Excel errors :))
:::
:::

:::aside
[Fang & Casadevall, 2011](https://journals.asm.org/doi/10.1128/iai.05661-11)
[Brembs et al. 2013](https://doi.org/10.3389/fnhum.2013.00291)
:::

## Current system is hugely wasteful

::: columns
:::{.column width=40%}
![](images/open_science/Maxwell.avif){height=16em}

Robert Maxwell in 1985. *Photograph: Terry O’Neill/Hulton/Getty*
::: 
:::{.column width=60%}
- worldwide sales > USD 19 billion
- dominated by five large publishing houses: Elsevier, Black & Wiley, Taylor & Francis, Springer Nature and SAGE
- Elsevier has a profit margin around 40 % (higher than Microsoft, Google and Coca Cola)
- about **USD 6 billion per year** goes to profits = 2 CERNs/year 
- APCs can be as high as $12,000
:::
:::

:::aside
[Hagve, 2015](https://tidsskriftet.no/en/2020/08/kronikk/money-behind-academic-publishing)
[Buranyi 2017](https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science)
:::

## Kleptistan (Binjistan) - I

::: columns
:::{.column width=80%}
![](images/open_science/Majka_Csurran_Cseppen.webm)
:::
:::{.column width=20%}

- an oligopoly of legacy publishers
- Elsevierstan
- Wileystan
- Taylorfrancistan
- Springerstan
- ...
:::
:::

:::aside
[Majka](https://www.youtube.com/watch?app=desktop&v=f2iQfEcO39A)
:::

## Kleptistan (Binjistan) - II

::: columns
:::{.column width=50%}
![](images/open_science/workflows-elsevier.png)
![](images/open_science/workflows-springernature1.png)
![](images/open_science/workflows-google.png)
:::
:::{.column width=50%}
- workflow monopoly
- tools to cover the entire academic workflow (e.g. Elsevier)
- high risk of vendor lock-in
- totalizing, homogenising workflows, extractive of research communities
:::
:::

:::aside
[Brembs et al. 2024](https://royalsocietypublishing.org/doi/full/10.1098/rsos.230206)
[Samuel A. Moore: Publishing Beyond the Market](https://press.umich.edu/Books/P/Publishing-Beyond-the-Market)
:::

## Kleptistan (Binjistan) - III

#### *or* <br> How to milk the same cow multiple times?

::: columns
:::{.column width=50%}
![](images/open_science/elsevier.png)
:::
:::{.column width=50%}
- scientists provide content for free
- scientist peer review for free
- scientists buy over-priced product as APC, subscription or 'transformative' deals
- publisher (now 'data analysis company') sells entire workflows to scientists
- publishers tracks scientists on its platforms
- sells the data to the employers (e.g. quality assessment) or third parties

:::
:::

:::aside
[Majka](https://www.youtube.com/watch?app=desktop&v=f2iQfEcO39A)
:::

## Unacceptable practices of data tracking by publishers


::: columns
:::{.column width=40%}
![](images/open_science/data-tracking.jpg)
[Watchthem](https://watchthem.live/data-tracking/)
*'Data gathering is an essential process, and most companies use it for their success.'*

::: 
:::{.column width=50%}

-  tracking site visits via authentication systems 
- detailed real-time data on the information behaviour of individuals and institution
- page visits, accesses, clicks, downloads, etc. 
- assembly of granular profiles of academic behaviour 
- without user consent
- selling the data, e.g. RELX – the parent company of Elsevier – establishes PURE at universities around the world
- to provide 'insights' into the entire research cycle
- RELX now also sells data to ICE...
:::
:::

:::aside
[DFG Report on Data Tracking](https://www.dfg.de/resource/blob/174924/d99b797724796bc1a137fe3d6858f326/datentracking-papier-en-data.pdf)
:::


## The problem is the system

::: columns
:::{.column width=40%}
![](images/open_science/books-1200x800.jpeg)
::: 
:::{.column width=60%}
- journal publishing system is fundamentally broken
- a legacy system that prevents science from meeting its true potential for society
- about 40,000 journals
- public trust problem
- science publishing must be built anew
- illusion of truth and finality
- artificial scarcity
- narrow formats
- incomplete information
- prestige and journal-rank fallacies
:::
:::

:::aside
[Seemay Chou, Astera, 'Scientific Publishing: Enough is Enough'](https://astera.org/scientific-publishing-enough-is-enough/)
:::


## What would a better system look like?

<br>

- data, code and text are shared, indexed, archived and discoverable
- analyses and workflows are also shared
- reagents (e.g. plasmids), strains (e.g. mutants) shared
- open-source software
- maximise reproducibility
- text + data + code = publication
- publications openly accessible, not behind a paywall
- affordable publishing (not hijacked by corporate for-profit publishers)
- preprints = publication, followed by post-publication peer review


## One example - the Uniprot database

::: columns
:::{.column width=70%}

![](images/open_science/uniprot.png)
::: 
:::{.column width=30%}
- a comprehensive resource for protein sequence and annotation data
- entries uniquely identified by a stable URL
- rich metadata that is both human-readable and machine-readable
- shared vocabularies and ontologies
- interlinking with more than 150 different databases
- © 2002 – 2026 UniProt consortium
:::
:::

:::aside
[UniProt Consortium, 2015](https://doi.org/10.1093/nar/gku989)
:::


## A history of Open Access --- The Budapest Open Access Initiative

::: columns
:::{.column width=70%}
![](images/open_science/BOAI.png)
- https://www.budapestopenaccessinitiative.org/
<br>*February 14, 2002*
<br>Budapest, Hungary

::: 
:::{.column width=30%}

- removing barriers to literature
- free and unrestricted online availability = **open access**
- the costs of providing OA to literature are far lower than the costs of traditional publishing (printed press)
- opportunity to save money and expand the scope of dissemination 
- recommendations: **self-archiving** (I.) and a new generation of **open-access journals** (II.)
:::
:::

## The launch of PLoS

![](images/open_science/Plos_open_letter.png){height=20em}

## Paywalls and the story of Aaron Swartz

::: columns
:::{.column width=30%}
![](images/open_science/AaronSwartzPIPA.jpg)
:::
:::{.column width=70%}

- in 2011, 24 y old internet hacktivist Aaron Swartz was arrested at MIT
- he downloaded several million articles from an online archive (JSTOR)
- legal troubles
- Swartz committed suicide in 2013
- the internet was created so that scientists could communicate their research results with each other
- billions of videos of cats for free, research results behind paywalls
- (GPT-4o showed an 82% recognition rate for paywalled content)
:::
:::

:::aside
[Michael Eisen: The Past, Present and Future of Scholarly Publishing](https://www.michaeleisen.org/blog/?p=1346)
:::

## The politicians weigh in - Plan S

- Plan S was initiated in 2018 as a political solution to the OA problem
- funders mandate immediate open access
- proposal to cap APC (article processing charge)
- publishers whine that this would hurt their profit
- scrap the cap
- let the 'market' solve it (it didn't)
- 'prestige' journals can charge as much as they like (Nature-$12,690; Cell-$11,400)

![](images/open_science/Logo_PlanS.png){height=6em}

:::aside
[Plan S by cOAlition S](https://www.coalition-s.org/)
:::

## OA has been hijacked by publishers

::: columns
:::{.column width=60%}
![](images/open_science/publications_by_OA_category.png)
::: 
:::{.column width=40%}
- Diamond: OA journal without an APC
- Green: not openly accessible from the publisher website but a free copy is accessible via a repository
- Gold: OA journal with APC (**profits can remain high!**)
- Hybrid: some papers OA others not (**profits can remain high!**)
- Bronze: free to read, no identifiable licence
- 'transformative agreements'
:::
:::

:::aside
[UNESCO - Open Science Outlook 1](https://unesdoc.unesco.org/ark:/48223/pf0000387324)
:::

## Towards some solutions...

<br><br><br>

### What should we do now?

## What should scientists and institutions do? 
### for the realist:

#### Safest bet: buy RELX stocks
(RELX: parent company of Elsevier)

![](images/open_science/relx_stocks.png){height=400}


## We have the solution, but not the balls to implement it

<br>

- under ‘closed’ models, institutions spend a lot of money on publishing 
- transitioning those funds to support community-led diamond OA, could fully support a global shift to OA 
- strenghten scholarly infrastructure for code, data, interoperability etc.
- huge potential for cost savings (Schimmer et al. 2015)
- publishing in the hand of public institutions
- USD 6 billion/year is a lot of money for that
- would also solve the problems with predatory publishers

:::aside
[UNESCO - Open Science Outlook 1](https://unesdoc.unesco.org/ark:/48223/pf0000387324)
:::

## What should scientists and institutions do? 
### for the idealist:

#### Taking back control

::: columns
:::{.column width=40%}
![](images/open_science/openaire.png)
::: 
:::{.column width=60%}
- Public institutions (universities, libraries, funders etc.) should take back control of the digital scholarly infrastructure
- create conditions of open competition for private sector (not oligopoly of a few publishers)
- control data, text, code, citation metrics, scholarly workflows, databases, standards etc.
- cancel all subscriptions and use money to fund databases, libraries, publishing etc.
- support initiatives like OpenAIRE
- build community, the commons -> publishing is community, care
:::
:::

:::aside
[OpenAIRE](https://www.openaire.eu/)
:::


## New approaches to research assessment

<br>

::: columns
:::{.column width=60%}

![](images/open_science/dora.png)
::: 
:::{.column width=40%}
- the San Francisco Declaration on Research Assessment
- eliminate the use of journal-based metrics (IF) in funding, appointment, and promotion decisions
- assess research on its own merits rather than based on the journal
- capitalize on the opportunities provided by online publication (e.g. relax limits on the number of words, figures, and references)
:::
:::

:::aside
[DORA](https://sfdora.org/read/)
:::


## Chasing False Metrics --- the Prestige Game

::: columns
:::{.column width=40%}
![](images/open_science/National_Cancer_Institute_director_Harold_E._Varmus_(2).jpg){height=300}

[Harold Varnus](https://en.wikipedia.org/wiki/Harold_E._Varmus#Publication_practices_in_science)<br>
*"We need to get away from false metrics and return to the task of looking at our colleagues' work closely."* 

::: 
:::{.column width=50%}
- we believe the most important work is published in so-called ‘high-impact’ journals
- ceding judgments to journal editors
- we have to eliminate the current situation in which the fate of researcher and their trainees depends on publishing in certain journals
:::
:::

:::aside
[Harold Varnus, 2019](https://pmc.ncbi.nlm.nih.gov/articles/PMC6451421/)
:::



## eLife

::: columns
:::{.column width=60%}
![](images/open_science/elife.png)

- funded by HHMI, Wellcome Trust, MPS, K&A Wallenberg Foundation

::: 
:::{.column width=40%}
- https://elifesciences.org/
- **The eLife process has five steps:**
  - Submission or transfer of a preprint from bioRxiv 
  - Peer review (eLife editors - who are all active researchers - discuss new submissions and decide which will be peer reviewed)
  - Publication of Reviewed Preprint
  - Publication of revised version
  - Publication of Version of Record
  - papers published together with eLife Assessment
  - eLife has no IF! (good!!)
  
:::
:::



## Sharing code in an ideal world - federated GitLab servers

<br>

::: columns
:::{.column width=60%}


![](images/open_science/git_on_the_server.png)
::: 
:::{.column width=40%}

- Institutions should host their **GitLab server** for code
- (**GitLab** is a database-backed web application running *git*)
- (*git* is a Distributed Version Control Systems)
- servers should be federated
- European (-> world-wide) network of research/education institutions and libraries
- code shared upon publication in a permanent repo with DOI
:::
:::

:::aside
[Chacon & Straub - Pro Git Book](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F)
:::


## Code with persistend DOI

<br>

::: columns
:::{.column width=60%}


![](images/open_science/zenodo.png)
::: 
:::{.column width=40%}

- Permanent repository for data, text and code
- integration with **GitHub**
- version control
- **Safe** — your research is stored safely for the future in CERN’s Data Centre for as long as CERN exists
- citeable
- usage statistics
:::
:::


## What is the solution? - The Fediverse for Science

::: columns
:::{.column width=30%}
![](images/open_science/fediverse.png)
::: 
:::{.column width=70%}
<br>

- a federated infrastructure
- run by public institutions (universities, libraries etc.)
- for communication (microblogging = Mastodon)
- for code (GitLab), data (e.g. Omero), text (preprint servers) etc.
- taking back control of scholarly infrastructure
:::
:::

:::aside
[Imagec credit: @FediTips](@FediTips@social.growyourown.services)
:::

## Towards a new, federated scholarly infrastructure

::: columns
:::{.column width=50%}
![](images/open_science/rsos230206f03.jpg)
::: 
:::{.column width=50%}
- plan for a federated scholarly information network
- a system that cannot be taken over by corporations
- designed redundantly
- open standards
- "a decentralized, resilient, evolvable network that is interconnected by open standards and open-source norms under the governance of the scholarly community"

:::
:::

:::aside
[Brembs et al. 2023](https://royalsocietypublishing.org/doi/full/10.1098/rsos.230206)
:::


## One example for publishing -  Open Research Europe (ORE)

::: columns
:::{.column width=60%}
![](images/open_science/ORE.png)

- open access publishing venue for EC-funded researchers
- no author or reader fees
- Diamond (but authors need to be EC funded)
- maintained by the European Commission
- Wellcome Open Research (https://wellcomeopenresearch.org/) is similar, maintained by the Wellcome Trust
- but too centralised and no community behind it
::: 
:::{.column width=30%}
<br>

- open up access methods, results, publications, data, software, materials, tools and peer reviews
- standard tender process held regularly
- no lock-in with a single publisher
- regular procurement processes, no monopoly, fair prices
:::
:::

:::aside
[]()
:::


## An European Infrastructure for Open Science

::: columns
:::{.column width=60%}
<br>

![](images/open_science/EOSC_EU_Node.png)
https://open-science-cloud.ec.europa.eu/
::: 
:::{.column width=40%}
- **Available Services:**
  - File Sync & Share 
  - Interactive Notebooks 
  - Large File Transfer 
  - Virtual Machines 
  - Cloud Container Platform 
  - Bulk Data Transfer 
:::
:::



## ...still early days


![](images/open_science/eu_open_science.png)

## While we wait...


::: columns
:::{.column width=70%}

![](images/open_science/approach_to_publications.png)


::: 
:::{.column width=30%}

- individual labs can change behaviour
- my lab has completely switched to publishing preprints and in OA-only not-for-profit journals
- raise your voice in hiring/promotion committees for DORA principles
:::
:::

:::aside
[Our Approach to Publication](https://www.cos.uni-heidelberg.de/en/research-groups/gaspar-jekely/our-approach-to-publication)
:::

## Further reading

![](images/open_science/Moore_Publishing_Beyond_the_Market_cover1_rb_fullcover.jpg){height=13em}

[Samuel A. Moore: Publishing Beyond the Market](https://press.umich.edu/Books/P/Publishing-Beyond-the-Market)


US library needs to cut subscriptions except to Elsevier etc.
https://www.science.org/content/article/doge-order-leads-journal-cancellations-u-s-agricultural-library

Move away from US cloud
https://www.reuters.com/world/europe/dutch-parliament-calls-end-reliance-us-software-2025-03-18/
